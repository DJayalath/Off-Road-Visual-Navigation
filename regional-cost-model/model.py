################################################################################
#
# (c) Copyright University of Southampton, 2022
#
# Copyright in this software belongs to the University of Southampton,
# Highfield, University Road, Southampton, SO17 1BJ, United Kingdom
#
# Created By : Dulhan Jayalath
# Date : 2022/04/27
# Project : Real-time Neural Visual Navigation for Autonomous Off-Road Robots
#
################################################################################

# ------------------------------------------------------------------------------
# Creates and trains a convolutional model for regional cost prediction based
# on MobileNetV3.
# Inputs:
# - Low-viewpoint forest depth dataset -> https://zenodo.org/record/3945526
# - labels_train.json / labels_test.json -> Generated by label.py
# Outputs:
# - model.hdf5 -> learned weights for regional cost prediction model
# - hist.pkl -> model training history
# Requirements:
# - Extract all the RGB files in the dataset into one folder called 'rgb'
#   and all the depth maps into another folder at the same level called 'depth'
#-------------------------------------------------------------------------------

# FIXME: Change this to directory of Low-viewpoint forest depth dataset rgb files
RGB_TRAIN = 'train/rgb'
RGB_TEST = 'test/rgb'

import cv2
import tensorflow as tf
from model_datagen import RegressionGenerator

print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

# Make sure this is equal to the square root of N in the paper.
NUM_STRIPS = 8

# Input size. 224x224 recommended for MobileNetV3
N = 224

# Preprocess for MobileNetV3 including resizing of images
def preprocess(x):
    x = cv2.resize(x, (N, N))
    x = tf.keras.applications.mobilenet_v3.preprocess_input(x)
    return x

# Create a model as described in the paper
def create_model():

    # Base: MobileNetv3
    base_model = tf.keras.applications.MobileNetV3Small(weights='imagenet', include_top=False, input_shape=(N, N, 3))
    x = base_model.output

    # Aggregate features of base
    x = tf.keras.layers.GlobalAveragePooling2D()(x)

    # N output heads with own MLPs
    outputs = []
    for i in range(NUM_STRIPS ** 2):
        c = tf.keras.layers.Dense(64, activation=tf.keras.activations.relu)(x)
        c = tf.keras.layers.Dense(128, activation=tf.keras.activations.relu)(c)
        c = tf.keras.layers.Dense(128, activation=tf.keras.activations.relu)(c)
        cost = tf.keras.layers.Dense(1, name=f'cost_{i}', activation=tf.keras.activations.linear)(c)

        outputs.append(cost)

    return tf.keras.Model(inputs=base_model.input, outputs=outputs)

def train():

    # Load data
    train_ds = RegressionGenerator(RGB_TRAIN, f'./labels_train.json', preprocess, 32)
    test_ds = RegressionGenerator(RGB_TEST, f'./labels_test.json', preprocess, 32)

    # Construct model
    model=create_model()

    # Fine tune, or train entire net?
    for layer in model.layers[:20]:
        layer.trainable=False
    for layer in model.layers[20:]:
        layer.trainable=True

    # Set loss function and metrics to track
    loss = {}
    metrics = {}
    for i in range(NUM_STRIPS ** 2):

        loss[f'cost_{i}'] = tf.keras.losses.MeanAbsoluteError()

        if i == 0:
            metrics[f'cost_{i}'] = tf.keras.metrics.MeanAbsolutePercentageError()

    # Compile model
    model.compile(loss=loss, optimizer=tf.keras.optimizers.Adam(), metrics=metrics)

    # Meta
    filepath = f"model.hdf5"
    checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_root_mean_squared_error', verbose=0, save_weights_only=False, save_best_only=False, mode='auto')
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir="./tflogs")

    # Fit model
    history = model.fit(train_ds, validation_data=test_ds, epochs=100, callbacks = [checkpoint, tensorboard_callback] )

    # Save history
    import pickle
    with open(f'hist.pkl', 'wb') as file_pi:
        pickle.dump(history.history, file_pi)


if __name__ == "__main__":
    train()